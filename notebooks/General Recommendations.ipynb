{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Import CSV\n",
    "file_path = '/Users/phani/Downloads/beer_reviews/beer_reviews.csv'\n",
    "beer_data = pd.read_csv(file_path, delimiter=',', encoding='utf-8')\n",
    "\n",
    "#Split DataFrames\n",
    "_reviews = ['review_overall', 'review_aroma', 'review_appearance', 'review_palate', 'review_taste']\n",
    "_attribs = ['beer_style', 'beer_abv']\n",
    "_ids = ['brewery_name', 'beer_name', 'beer_beerid']\n",
    "_users = ['review_profilename']\n",
    "beer_data.drop(['brewery_id', 'review_time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Recommendation\n",
    "\n",
    "### Recommend beers based on overall reviews from all reviewers\n",
    "\n",
    "A simple ordering of data based on review_overall should give us a list with beers and their corresponding ranking in the list. However, the review_overall values for the beers are scattered and all the beers are not rated by all the users. \n",
    "Hence, we calculate the means of review_overall values for a given beer and assign that value as the overall rating for that beer. Then we rank the beers based on review_overall and then pick the top few beers as recommendations based on this data.\n",
    "\n",
    "#### Data Cleaning \n",
    "Number of reviews are not same for all beers. So, we will calculate the sample mean from the number of reviews we gathered for a beer to assign one overall_review for each beer. However, some beers have only one review where as others have more than one reviews. Hence, we need to clean up the data to include only those beers where we can calculate the mean within a certain margin of error. \n",
    "\n",
    "#### Choosing Sample Means: \n",
    "The statistics way to chose the threshold number of reviews (min number of samples) is to compute the minimum number of required reviews for a beer to predict the mean with 95% confidence interval. \n",
    "\n",
    "We use this formula: ($\\frac{\\sigma^2 * Z^2}{m^2}$), where $\\sigma$ is the standard deviation of the sample, Z-score for a confidence interval of 95% is 1.96 and m is the allowed margin of error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a new dataframe with four attributes\n",
    "samplesDF = beerData[[\"beer_beerid\",\"beer_name\",\"review_overall\", \"review_profilename\"]]\n",
    "\n",
    "# drop duplicate reviews for the same beer\n",
    "samplesDF = samplesDF.drop_duplicates([\"beer_beerid\",\"review_profilename\"])\n",
    "\n",
    "# set indices for determining levels\n",
    "samplesDF = samplesDF.set_index([\"beer_beerid\",\"beer_name\"])\n",
    "\n",
    "# Calculate nSamples, sampleMeans, sampleStdDev\n",
    "\n",
    "nSamples = samplesDF.groupby(level=0).count().to_dict()\n",
    "sampleMeans = samplesDF.groupby(level=0).mean().to_dict()\n",
    "sampleStdDev = samplesDF.groupby(level=0).std()\n",
    "\n",
    "# Define Margin of Error and Z-score for 95% confidence interval\n",
    "mError = 0.1\n",
    "zScore = 1.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. filter out sampleMeans with less number of reviews than minimum required to achieve 95% confidence interval \n",
    "#### 2. sort sampleMeans and rank beer_ids from the sorted sampleMeans\n",
    "#### 3. reject samples with std dev = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampleMeansTemp = {}\n",
    "for key in nSamples.keys(): \n",
    "    if key == \"review_overall\": # we are only interested in overall_review\n",
    "        for beerID in nSamples[key].keys(): # get the values - beer_beerid and overall review\n",
    "            if sampleStdDev[key][beerID] > 0:\n",
    "                nSamplesRequired = (sampleStdDev[key][beerID] * zScore/mError)**2\n",
    "            if nSamples[key][beerID] > nSamplesRequired:\n",
    "                sampleMeansTemp[beerID] =  sampleMeans[key][beerID]\n",
    "\n",
    "# redefine sampleMeans by sorted overall_reviews \n",
    "sampleMeans = sorted(sampleMeansTemp.items(), key=lambda x: x[1] , reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Filter out the beerIDs that are not included in sampleMeans list\n",
    "2. make a new dataframe \n",
    "\n",
    "#### Note: appending rows to make a new data frame takes a lot of time. \n",
    "3. So take the original data frame and drop the rows by comparing beerIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviewBeerIDs = [beerKey[0] for beerKey in sampleMeans]\n",
    "# drop the duplicate beerIDs \n",
    "newBeerDF = beerData.drop_duplicates([\"beer_beerid\"])\n",
    "beerIDsAll = newBeerDF.beer_beerid.tolist()\n",
    "\n",
    "# list the iDs that we need to discard\n",
    "discardBeerIDs = [beerID for beerID in beerIDsAll if beerID not in reviewBeerIDs]\n",
    "newBeerDF = newBeerDF.set_index([\"beer_beerid\"])\n",
    "newBeerDF = newBeerDF.drop(discardBeerIDs)\n",
    "\n",
    "#drop other labels and leave only few for visualization\n",
    "newBeerDF = newBeerDF.drop(['brewery_id','review_time', 'review_overall','review_aroma','review_taste',\n",
    "                    'review_palate','review_profilename','beer_abv','review_appearance'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a column review_overall with values from sampleMeans\n",
    "review_overall = []\n",
    "for beerIndex in newBeerDF.index.tolist():\n",
    "    for keyIndex in range(len(sampleMeans)):\n",
    "        if sampleMeans[keyIndex][0] == beerIndex:\n",
    "            review_overall.append(sampleMeans[keyIndex][1])\n",
    "\n",
    "# add the column review_overall values from sampleMeans list\n",
    "newBeerDF['review_overall'] = review_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the top ten beers in the list - General Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sort the dataframe by overall reviews and print the top ten beers in the list\n",
    "newBeerDF = newBeerDF.sort_values(by='review_overall', ascending=False)\n",
    "newBeerDF.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "\n",
    "### Find out which features are important in determining the overall quality of the beer\n",
    "\n",
    "In the reviews data set, we have four features listed for each beer: Appearance (or body), Aroma, Palate and Taste\n",
    "\n",
    "Here we will try to correlate the overall rating for a given beer with each of the four features and then decide which of the above four features is the most important in determining the overall quality of the beer.\n",
    "\n",
    "Since there are many users(reviewers) for each beer and the ratings are spread within a certain range of values, we will use the Samplemeans of the ratings for each beer as a representative value to develop correlation between features and overall rating. \n",
    "\n",
    "We can use two approaches: \n",
    "1. Compare the standardized $R^2$ values from the four features and rank them\n",
    "2. Starting with a model with n-1 features, compare the $\\Delta$ in $R^2$ when the left out feature is added and then chose the feature that results in the greatest $\\Delta$\n",
    "\n",
    "#### Data Cleaning \n",
    "We will use the same procedure for cleaning data and chosing sample means for building data and features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Features and Data Matrix\n",
    "# Create a new dataframe with the relevant features and other columns\n",
    "featureDF = beerData[[\"beer_beerid\", \"review_profilename\",'review_appearance','review_aroma', \n",
    "                      'review_palate','review_taste','review_overall']]\n",
    "featureDF = featureDF.drop_duplicates([\"beer_beerid\",\"review_profilename\"])\n",
    "featureDF = featureDF.set_index(\"beer_beerid\")\n",
    "\n",
    "# discard the beers that didn't meet our screening criterion of 95% confidence level\n",
    "# discardBeerIDs are taken from above\n",
    "featureDF = featureDF.drop(discardBeerIDs)\n",
    "featureDF = featureDF.reset_index()\n",
    "\n",
    "# Make the list of all beers that pass the screenign criterion.\n",
    "beerIDList = sorted(featureDF.beer_beerid.unique())\n",
    "\n",
    "# Reindex the dataframe for extracting features.\n",
    "featureDF = featureDF.set_index([\"beer_beerid\",\"review_profilename\"])\n",
    "\n",
    "#Debug Info:\n",
    "    #print(len(beerIDList),len(profileList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Means and Standard deviation\n",
    "featuresDict = featureDF.groupby(level=0).mean().to_dict()\n",
    "\n",
    "#Appearance\n",
    "appearanceSampleMeans = featuresDict['review_appearance']\n",
    "#Aroma\n",
    "aromaSampleMeans = featuresDict['review_aroma']\n",
    "#Palate\n",
    "palateSampleMeans = featuresDict['review_palate']\n",
    "#Taste\n",
    "tasteSampleMeans = featuresDict['review_taste']\n",
    "#Overall review for Data Matrix\n",
    "reviewSampleMeans = featuresDict['review_overall']\n",
    "\n",
    "# Construct a numpy matrix with features Sample Means\n",
    "featureMatrix = np.zeros(len(beerIDList*5)).reshape(len(beerIDList),5)\n",
    "featuresMeansDicts = [appearanceSampleMeans,aromaSampleMeans,\n",
    "                      palateSampleMeans,tasteSampleMeans]\n",
    "\n",
    "# Populate the first element of the feature matrix with beerID\n",
    "for beerIndex in range(len(beerIDList)):\n",
    "    featureMatrix[beerIndex][0] = beerIDList[beerIndex]\n",
    "    \n",
    "featureIndex = 1 # feature index in feature Matrix\n",
    "for featureDict in featuresMeansDicts:\n",
    "    for beerIndex in range(len(beerIDList)):\n",
    "        for key in featureDict.keys():\n",
    "            if key == beerIDList[beerIndex]:\n",
    "                featureMatrix[beerIndex][featureIndex] = featureDict[key]\n",
    "    featureIndex += 1\n",
    "\n",
    "# Construct the dataMatrix with Sample Means of overall review\n",
    "dataMatrix = np.zeros(len(beerIDList*2)).reshape(len(beerIDList),2)\n",
    "\n",
    "# Populate the first element of the Data matrix with beerID\n",
    "# Second element with the overall review\n",
    "#for beerIndex in range(len(beerIDList)):\n",
    "#    dataMatrix[beerIndex][0] = beerIDList[beerIndex]\n",
    "\n",
    "for beerIndex in range(len(beerIDList)):\n",
    "    dataMatrix[beerIndex][0] = beerIDList[beerIndex]\n",
    "    for key in reviewSampleMeans.keys():\n",
    "        if key == beerIDList[beerIndex]:\n",
    "            dataMatrix[beerIndex][1] = reviewSampleMeans[key]     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "X = np.array([featureMatrix[i][1:] for i in range(featureMatrix.shape[0])])\n",
    "# Standardize the feature matrix: subtract mean and make it unit variance. $X = \\frac{X-\\mu}{\\sigma}$\n",
    "X = StandardScaler().fit_transform(X) \n",
    "y = np.array([dataMatrix[i][1] for i in range(dataMatrix.shape[0])])\n",
    "\n",
    "# Transpose to index individual columns\n",
    "X = X.T\n",
    "\n",
    "for index in range(4):\n",
    "    X_feature = X[index]\n",
    "    X_feature = X_feature[:,np.newaxis]\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_feature, y)\n",
    "    score = regressor.score(X_feature,y)\n",
    "    xMin = X_feature.min() * regressor.coef_[0] + regressor.intercept_\n",
    "    xMax = X_feature.max() * regressor.coef_[0] + regressor.intercept_\n",
    "    \n",
    "    ax = fig.add_subplot(2,2,index+1)\n",
    "    ax.plot([X_feature.min(), X_feature.max()], [xMin, xMax],linewidth=3.0, color='k')\n",
    "    ax.plot(X[index], y, 'ro')\n",
    "\n",
    "    if index == 0:\n",
    "        ax.set_ylabel('Appearance')\n",
    "        ax.text(0,2,'$R^2$ = %.2f'%score)\n",
    "    elif index == 1:\n",
    "        ax.set_ylabel('Aroma')\n",
    "        ax.text(0,2,'$R^2$ = %.2f'%score)\n",
    "    elif index == 2:\n",
    "        ax.set_ylabel('Palate')\n",
    "        ax.text(0,2,'$R^2$ = %.2f'%score)\n",
    "    else:\n",
    "        ax.set_ylabel('Taste')\n",
    "        ax.text(0,2,'$R^2$ = %.2f'%score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = {0:\"Appearance\",1:\"Aroma\",2:\"Palate\",3:\"Taste\"}\n",
    "deltaR2 = []\n",
    "for index in range(4):\n",
    "    X_feature = np.delete(X.T,index,axis=1)\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_feature, y)\n",
    "    scoreOne = regressor.score(X_feature,y)\n",
    "    regressor.fit(X.T, y)\n",
    "    scoreTwo = regressor.score(X.T,y)\n",
    "    deltaR2.append(scoreTwo - scoreOne)\n",
    "    print(\"Change in $R^2$ value upon including \", features[index],\" = \", \"%.3f\"%deltaR2[index])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,2))\n",
    "ax = fig.add_subplot(111)\n",
    "width = 0.5\n",
    "ax.bar(list(features.keys()), deltaR2, width, color='r')\n",
    "ax.set_xticks([i+width*0.5 for i in list(features.keys())])\n",
    "ax.set_xticklabels(('Appearance', 'Aroma', 'Palate', 'Taste'))\n",
    "ax.set_xlabel(\"Beer Charateristics\")\n",
    "ax.set_ylabel(\"$\\Delta R^2$\")\n",
    "ax.set_title(\"Feature Importance ($ \\propto \\Delta R^2$)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
